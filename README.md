



# ğŸ“± ECGApp â€“ Mobile ECG Viewer & Classifier

**ECGApp** is a cross-platform mobile application (iOS ) for real-time ECG signal acquisition, processing, and classification using deep learning models.

---


## ğŸ“š Table of Contents
- [Key Features](#-key-features)
- [Used Deep Learning Models](#-used-deep-learning-models)
- [Datasets Used](#-datasets-used)
- [Evaluation & Metrics](#-evaluation--metrics)
- [Signal Format](#-signal-format)
- [Import & Interoperability](#-import--interoperability)
- [Use Cases](#-use-cases)
- [Tech Stack](#-tech-stack)
- [Medical Disclaimer](#-medical-disclaimer)


---

## ğŸ§  Key Features

* ğŸ”Œ Connect to external BLE ECG sensors (e.g., ESP32, Arduino)
* ğŸ“ˆ Real-time signal visualization (zoom, pan, rescale)
* âº Record ECG to local `.json` and `.dat` and `.hea` format
* ğŸ§  AI-based classification:

  * Heart **rhythm classification** (e.g. NSR, AF, PVC)
  * **Beat-type classification** near QRS centers (e.g. N, V, S)
   * **Waveform segmentation** per sample into `P`, `QRS`, `T` waves for morphological analysis
* ğŸ“‚ Browse, view, share or delete saved recordings

---

## ğŸ“¦ Used Deep Learning Models

### 1. Rhythm Classification â€“ `SE_MobileNet1D_noLSTM` (PyTorch)

Lightweight SE-enhanced MobileNet 1D CNN with demographic inputs.

* **Input**: 10-second 1-lead ECG (5000 samples of 500hz signal), age (normalized), sex (0/1)
* **Output**: Single-label rhythm class (softmax)
* **Deployment**: Converted via ONNX â†’ TensorFlow â†’ CoreML / TFLite
* **Datasets**: CPSC 2018, CPSC Extra, PTB-XL, Georgia Dataset

#### Architecture Summary:

```
â†’ Conv1D(1 â†’ 16, kernel=7, stride=2, padding=3)
  â†’ BatchNorm1d(16)
  â†’ SiLU

â†’ DepthwiseConv1D(16 â†’ 16, kernel=5, stride=2, padding=2, groups=16)
â†’ PointwiseConv1D(16 â†’ 32, kernel=1)
  â†’ BatchNorm1d(32)
  â†’ SiLU
â†’ SEBlock(32):
     â†’ AdaptiveAvgPool1d(1)
     â†’ Linear(32 â†’ 4) â†’ ReLU
     â†’ Linear(4 â†’ 32) â†’ Sigmoid
     â†’ Multiply input Ã— scale
â†’ Dropout(0.1)

â†’ DepthwiseConv1D(32 â†’ 32, kernel=5, stride=2, padding=2, groups=32)
â†’ PointwiseConv1D(32 â†’ 64, kernel=1)
  â†’ BatchNorm1d(64)
  â†’ SiLU
â†’ SEBlock(64):
     â†’ AdaptiveAvgPool1d(1)
     â†’ Linear(64 â†’ 8) â†’ ReLU
     â†’ Linear(8 â†’ 64) â†’ Sigmoid
     â†’ Multiply input Ã— scale
â†’ Dropout(0.1)

â†’ DepthwiseConv1D(64 â†’ 64, kernel=5, stride=2, padding=2, groups=64)
â†’ PointwiseConv1D(64 â†’ 128, kernel=1)
  â†’ BatchNorm1d(128)
  â†’ SiLU
â†’ SEBlock(128):
     â†’ AdaptiveAvgPool1d(1)
     â†’ Linear(128 â†’ 16) â†’ ReLU
     â†’ Linear(16 â†’ 128) â†’ Sigmoid
     â†’ Multiply input Ã— scale
â†’ Dropout(0.1)

â†’ DepthwiseConv1D(128 â†’ 128, kernel=5, stride=1, padding=2, groups=128)
â†’ PointwiseConv1D(128 â†’ 128, kernel=1)
  â†’ BatchNorm1d(128)
  â†’ SiLU
â†’ SEBlock(128):
     â†’ AdaptiveAvgPool1d(1)
     â†’ Linear(128 â†’ 16) â†’ ReLU
     â†’ Linear(16 â†’ 128) â†’ Sigmoid
     â†’ Multiply input Ã— scale
â†’ Dropout(0.1)


```

### 2. Beat-Type Classification â€“ CNN Model (Pytorch)

Trained on beats centered on QRS complexes from:

* MIT-BIH Arrhythmia Database (mitdb)

* INCART 12-lead Arrhythmia Database (incartdb)

* SVDB 

* **Input**: 1D ECG window centered at QRS (540 samples of 360 hz signal)

* **Output**: Beat class (N, V, S , F, Q )

* **Deployment**: Used for inference after R-peak detection

#### Architecture Summary:

```
ECGClassifier:
Input: (B, 1, T) (np. 540 prÃ³bek @ 360 Hz)



FEATURE EXTRACTION
â†’ Conv1D(1 â†’ 32, kernel=7, stride=2, padding=3)
â†’ BatchNorm1d(32) â†’ ReLU

â†’ ResidualBlock(32):
  â†’ Conv1D(32 â†’ 32, kernel=3, padding=1)
  â†’ BatchNorm1d(32) â†’ ReLU
  â†’ Conv1D(32 â†’ 32, kernel=3, padding=1)
  â†’ BatchNorm1d(32)
  â†’ Skip connection + ReLU

â†’ SEBlock(32):
  â†’ AdaptiveAvgPool1d(1)
  â†’ Conv1D(32 â†’ 4, kernel=1) â†’ ReLU
  â†’ Conv1D(4 â†’ 32, kernel=1) â†’ Sigmoid
  â†’ Multiply (channel-wise scaling)

â†’ Conv1D(32 â†’ 64, kernel=5, stride=2, padding=2)
â†’ BatchNorm1d(64) â†’ ReLU

â†’ ResidualBlock(64):
  â†’ Conv1D(64 â†’ 64, kernel=3, padding=1)
  â†’ BatchNorm1d(64) â†’ ReLU
  â†’ Conv1D(64 â†’ 64, kernel=3, padding=1)
  â†’ BatchNorm1d(64)
  â†’ Skip connection + ReLU

â†’ SEBlock(64):
  â†’ AdaptiveAvgPool1d(1)
  â†’ Conv1D(64 â†’ 8, kernel=1) â†’ ReLU
  â†’ Conv1D(8 â†’ 64, kernel=1) â†’ Sigmoid
  â†’ Multiply (channel-wise scaling)




CLASSIFICATION HEAD
â†’ AdaptiveAvgPool1d(1)
â†’ Flatten: (B, 64)

â†’ Linear(64 â†’ 32)
â†’ ReLU
â†’ Dropout(0.5)

â†’ Linear(32 â†’ num_classes)

Output:
â†’ Shape: (B, num_classes) â€“ logits of classes.

```

---

---

### 3. Waveform Segmentation â€“ UNet1D (PyTorch)
Lightweight 1D U-Net model for per-sample waveform classification trained on LUDB dataset.

* **Input**: 10-second 1-lead ECG segment (2000 samples of 500 Hz signal, lead II)
* **Output**: Per-sample waveform class (none, P, QRS, T) using softmax over 4 classes
* **Deployment**: Converted to CoreML (UnetModel.mlpackage) for real-time waveform segmentation
* **Datasets**: LUDB (Lobachevsky University Database), 200 manually annotated 12-lead ECGs



#### Architecture Summary:

```
UNet1D:
Input: (B, 1, 2000)


ENCODER / DOWNSAMPLING

â†’ Block 1:
  â†’ Conv1D(1 â†’ 4, kernel=9, padding=4)
  â†’ BatchNorm1d(4) â†’ ReLU
  â†’ Conv1D(4 â†’ 4, kernel=9, padding=4)
  â†’ BatchNorm1d(4) â†’ ReLU
  â†’ MaxPool1D(kernel=2)             # â†“ T/2

â†’ Block 2:
  â†’ Conv1D(4 â†’ 8, kernel=9, padding=4)
  â†’ BatchNorm1d(8) â†’ ReLU
  â†’ Conv1D(8 â†’ 8, kernel=9, padding=4)
  â†’ BatchNorm1d(8) â†’ ReLU
  â†’ MaxPool1D(kernel=2)             # â†“ T/4

â†’ Block 3:
  â†’ Conv1D(8 â†’ 16, kernel=9, padding=4)
  â†’ BatchNorm1d(16) â†’ ReLU
  â†’ Conv1D(16 â†’ 16, kernel=9, padding=4)
  â†’ BatchNorm1d(16) â†’ ReLU
  â†’ MaxPool1D(kernel=2)             # â†“ T/8

â†’ Block 4:
  â†’ Conv1D(16 â†’ 32, kernel=9, padding=4)
  â†’ BatchNorm1d(32) â†’ ReLU
  â†’ Conv1D(32 â†’ 32, kernel=9, padding=4)
  â†’ BatchNorm1d(32) â†’ ReLU
  â†’ MaxPool1D(kernel=2)             # â†“ T/16




BOTTLENECK

â†’ Conv1D(32 â†’ 64, kernel=9, padding=4)
â†’ BatchNorm1d(64) â†’ ReLU
â†’ Conv1D(64 â†’ 64, kernel=9, padding=4)
â†’ BatchNorm1d(64) â†’ ReLU




DECODER / UPSAMPLING

â†’ TransposedConv1D(64 â†’ 32, kernel=8, stride=2, padding=3)
â†’ Pad to match enc4 â†’ Concat([up, enc4]) â†’ (64 channels)
â†’ Conv1D(64 â†’ 32) â†’ BN â†’ ReLU â†’ Conv1D â†’ BN â†’ ReLU

â†’ TransposedConv1D(32 â†’ 16, kernel=8, stride=2, padding=3)
â†’ Pad to match enc3 â†’ Concat([up, enc3]) â†’ (32 channels)
â†’ Conv1D(32 â†’ 16) â†’ BN â†’ ReLU â†’ Conv1D â†’ BN â†’ ReLU

â†’ TransposedConv1D(16 â†’ 8, kernel=8, stride=2, padding=3)
â†’ Pad to match enc2 â†’ Concat([up, enc2]) â†’ (16 channels)
â†’ Conv1D(16 â†’ 8) â†’ BN â†’ ReLU â†’ Conv1D â†’ BN â†’ ReLU

â†’ TransposedConv1D(8 â†’ 4, kernel=8, stride=2, padding=3)
â†’ Pad to match enc1 â†’ Concat([up, enc1]) â†’ (8 channels)
â†’ Conv1D(8 â†’ 4) â†’ BN â†’ ReLU â†’ Conv1D â†’ BN â†’ ReLU



OUTPUT

â†’ Final Conv1D(4 â†’ num_classes, kernel=1)  # Pointwise convolution
â†’ Output shape: (B, num_classes, T)
â†’ Permute to (B, T, num_classes) for per-sample classification




```


---


---

## ğŸ“Š Datasets Used

| Dataset         | Role                  | Format | Notes                             |
|-----------------|-----------------------|--------|-----------------------------------|
| CPSC 2018       | Rhythm classification | mat    | 1-lead, SNOMED codes              |
| CPSC 2018 Extra | Rhythm classification | mat    | Additional records                |
| PTB-XL          | Rhythm classification | mat    | With age and sex demographic data |
| Georgia         | Rhythm classification | mat    | 12-lead                           |
| MIT-BIH (mitdb) | Beat classification   | dat    | 360 Hz, QRS annotated             |
| INCARTDB        | Beat classification   | dat    | 12-lead, annotated                |
| SVDB            | Beat classification   | dat    | Supraventricular focus            |
| LUDB            | Wave classification   | dat    | Waves focus                       |


All signals were:
- Resampled to 500 Hz (rhythm and wave) or 360 Hz (beat)
- Normalized and denoised using wavelet transform (`bior2.6`)
- Lead II extracted and used as input

---


## âš ï¸ Medical Disclaimer

**This application is *not* a certified medical device.**

* It has not been evaluated by any regulatory authorities (FDA, CE, EMA).
* It is not intended for:

  * Diagnosing or monitoring medical conditions
  * Emergency or therapeutic use
* AI predictions are experimental and may be inaccurate or misleading.
* Signal quality may be affected by noise, motion, or hardware limitations.
* If you experience symptoms (e.g., chest pain, arrhythmia, dizziness), contact a qualified physician immediately.

> This app is intended **only for research, prototyping, and educational purposes**.

Use of this application is entirely at your own risk.

---

## ğŸ§ª Use Cases

* ECG signal acquisition for biomedical prototyping
* BLE hardware integration (Arduino/ESP32)
* Testing real-time AI classification on mobile
* Study of rhythm and beat-type classification models

---

## ğŸ”§ Tech Stack

* SwiftUI + CoreBluetooth (iOS frontend)
* PyTorch, Keras/TensorFlow (model training)
* ONNX â†’ TensorFlow â†’ CoreML / TFLite (deployment)
* WFDB, SciPy, PyWavelets (signal preprocessing)

---


## ğŸ” Evaluation & Metrics

Each model is evaluated with task-specific metrics:

### Rhythm Classification
- âœ… Accuracy, macro/weighted F1-score  
- âœ… Per-class precision and recall  
- âœ… Confusion matrix (10-class)  
- âœ… NSR fallback threshold:  
  - `softmax max < 0.4` â†’ fallback to NSR (`59118001`)

### Beat-Type Classification
- âœ… Per-beat accuracy (N, V, S, F, Q)  
- âœ… Inference on 540-sample QRS-centered segments  
- âœ… Real-time aggregation of beat-type predictions

### Waveform Segmentation
- âœ… Sample-wise F1-score and accuracy  
- âœ… Onset/offset match with Â±150 sample tolerance  
- âœ… Segment-wise precision, recall, and F1-score  
- âœ… Overlay visualization: predicted vs. true waveforms

---



## ğŸ“‚ Signal Format

### Saved recordings are stored in `.json` format:

```json
{
  "fs": 500,
  "leads": ["II"],
  "signals": [[0.003, 0.002, 0.005]],
  "start_time": "2025-06-01T12:01:00Z",
  "end_time": "2025-06-01T12:01:10Z"
}
```
* **fs**: Sampling frequency (Hz)
* **leads**: Array of lead names (e.g., ["II"])
+ **signals**: List of signal arrays (1 per lead)
* **start_time**, end_time: ISO 8601 timestamps

---
### Saved recordings are stored in `.hea` format:
```
record123 1 500 5000
record123.dat 16 1000 16 0 0 200 0 II
# age: 26
# sex: M
# duration: 10 seconds
# start_time: 2025-06-01T12:01:00Z
# end_time: 2025-06-01T12:01:10Z
# Recorded via ECG mobile app

```
* **Line** 1: <record_name> <n_signals> <fs> <n_samples>
* **Line** 2: <file> <format> <gain> <bit_res> <adc_zero> <init_val> <adc_resolution> 0 <lead>
* **Comments** (#) include age, sex, start/end time, duration
---
### Saved recordings are stored in `.dat` format:

Signal samples saved as Int16, scaled by gain
Written in little-endian format
Lead order matches .hea

---

## ğŸ“¥ Import & Interoperability

The app supports importing ECG files in multiple formats:

- `.dat` + `.hea` (WFDB-compliant):
  - e.g., MITDB, INCARTDB, LUDB
- `.json` format exported by the ECGApp

All imported signals are parsed and normalized, including:
- Sampling frequency (`fs`)
- Number of samples
- Gain, resolution, zero offset
- Lead name (e.g., II)

Supported encoding:
- ğŸ§© 16-bit integer (`format 16`)
- âœ… Single-lead inputs (Lead II preferred)

---


## â˜ï¸ iCloud & File Sharing

ECGApp fully integrates with the iOS Files system, enabling secure cloud-based data access:

- ğŸ“¤ **Export ECG recordings** to iCloud Drive for backup or manual inspection  
- ğŸ“¥ **Import** `.dat` / `.hea` / `.json` files from iCloud, USB, or AirDrop  
- ğŸ” Seamlessly **transfer data** between iPhone, iPad, or Mac  
- ğŸ“ Files are available under **Files â†’ ECGApp â†’ On My iPhone**

This makes it easy to analyze, review, or back up ECG sessions securely.

---

## ğŸ›¡ï¸ Data Privacy

All ECG data is processed and stored **locally on the userâ€™s device**.  
No recordings or personal information are sent to external servers.

- ğŸ“± All AI inference and signal analysis are performed **on-device**
- â˜ï¸ If the user chooses to share recordings via iCloud, AirDrop, or Files, **the transfer is secure and user-controlled**
- ğŸ›‘ The app does **not collect, upload, or transmit** any data automatically
- âœ… No third-party analytics, tracking, or background syncing

Users have full control over their data:

- ğŸ“‚ Access and manage saved recordings (`.json`, `.dat`, `.hea`)
- ğŸ—‘ Manually delete or export any file
- ğŸ”’ Bluetooth connections are limited to **approved UUIDs only**

> Your data remains yours â€” private, secure, and under your control.


---

## ğŸ“¦ Future Work (Planned)

- ğŸ’¡ Multi-lead ECG support (e.g., V1, V5, aVR)
- ğŸ§ª Personalized on-device model fine-tuning
- ğŸ©º AI-based tagging of symptoms and abnormalities
- ğŸ“ˆ Long-term trend tracking and visualization


---

## ğŸ“œ License

MIT License â€” For research and non-commercial use only.



---

## Authors

Marcin Sztukowski 
student of Jagiellonian University in Krakow
